{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "048f4607-8f11-4671-a69f-54481db783b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import get_client\n",
    "\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from db.milvus_handler import MilvusHandler\n",
    "from langchain.messages import SystemMessage\n",
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from messages_class import MessagesState\n",
    "from langchain.messages import HumanMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# === Init Langfuse ===\n",
    "\n",
    "langfuse = get_client()\n",
    "# langfuse_client = \n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# === Init Milvus ===\n",
    "milvus = MilvusHandler()\n",
    "\n",
    "\n",
    "\n",
    "# EMBEDING / AI\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"CHATBOT_MODEL_GENERATIVE\")\n",
    "embedding_model = os.getenv(\"CHATBOT_MODEL_EMBEDDING\")\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b5fbd47-37f0-48c4-8a38-8987c9e0c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = init_chat_model(\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "messages = [SystemMessage(content=\"Eşti un sistem profesionist de avocatură care vorbeşte limba română şi este specializat în Codul Penal şi legislaţia română.\")]\n",
    "\n",
    "query = HumanMessage(content=\"ce se intampla daca fur ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfa327eb-aa9a-448e-af41-0291e14fad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_context(embedding):\n",
    "    context = milvus.search(embedding, top_k=2)\n",
    "    return context\n",
    "    \n",
    "def get_chatbot_answer(query: str, articles: list):\n",
    "    \"\"\"\n",
    "    Generates a concise, professional answer in Romanian to a legal query using provided articles.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's legal question.\n",
    "        articles (list): List of relevant articles or articles to use for context.\n",
    "\n",
    "    Returns:\n",
    "        str: The chatbot's answer in Romanian.\n",
    "    \"\"\"\n",
    "    context = str(articles)\n",
    "    completion = agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    --IDENTITY: A romanian lawyer that answers short and concise.\n",
    "                    --TASK: You are going to answer the USER_QUERY by using CONTEXT.\n",
    "                    --USER_QUERY: {query}\n",
    "                    --CONTEXT: {context}\n",
    "                \"\"\",\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        config={\"callbacks\": [langfuse_handler]},\n",
    "    )\n",
    "    return completion[\"messages\"][-1].content\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    \"\"\"\n",
    "    Generates an embedding vector for the given text using OpenAI's embedding model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to embed.\n",
    "        model (str, optional): The embedding model to use. Defaults to \"text-embedding-3-large\".\n",
    "\n",
    "    Returns:\n",
    "        list: The embedding vector for the input text.\n",
    "    \"\"\"\n",
    "    with langfuse.start_as_current_observation(\n",
    "        as_type=\"embedding\",\n",
    "        name=\"embedding-generation\"\n",
    "    ) as obs:\n",
    "        try:\n",
    "            vector = embeddings.embed_query(text)\n",
    "            obs.update(output=vector)\n",
    "            return vector\n",
    "        except Exception as exc:\n",
    "            print(f\"Error generating embedding: {exc}\")\n",
    "            raise\n",
    "             \n",
    "def run_chatbot(question: str):\n",
    "    \"\"\"\n",
    "    Generates and prints an answer to a legal question using embeddings and a chatbot.\n",
    "\n",
    "    Args:\n",
    "        question (str): The legal question to be answered.\n",
    "    \"\"\"\n",
    "    embedding = get_embedding(question)\n",
    "    context = get_context(embedding)\n",
    "    print(context)\n",
    "    answer_from_gpt = get_chatbot_answer(question, context)\n",
    "    print(answer_from_gpt)\n",
    "    return answer_from_gpt, context\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "148f8e75-aa4a-4162-a610-fa5d9ca39271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"run_chatbot\", run_chatbot)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"\")\n",
    "agent_builder.add_edge(\"llm_call\", \"run_chatbot\")\n",
    "agent_builder.add_edge(\"run_chatbot\", END)\n",
    "\n",
    "# Compile the agent\n",
    "agent_graph = agent_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0292009-1879-4645-8275-c0f548d763bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the agent\n",
    "display(Image(agent_graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0d7ad22-f00e-4c3e-a184-87680529e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating embedding: ('Input text for embedding is empty.', \"text is {'messages': [HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={}), ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessage(content='Eşti un sistem profesionist de avocatură care vorbeşte limba română şi este specializat în Codul Penal şi legislaţia română.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={})])], 'llm_calls': 1}\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Input text for embedding is empty.', \"text is {'messages': [HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={}), ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessage(content='Eşti un sistem profesionist de avocatură care vorbeşte limba română şi este specializat în Codul Penal şi legislaţia română.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={})])], 'llm_calls': 1}\")",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m      2\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mCe se intampla daca fur ?\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m new_state = \u001b[43magent_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m new_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      5\u001b[39m     m.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\cod\\chatbotRevive\\ChatBot\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mrun_chatbot\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_chatbot\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     73\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    Generates and prints an answer to a legal question using embeddings and a chatbot.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m        question (str): The legal question to be answered.\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     embedding = \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     context = milvus.search(embedding, top_k=\u001b[32m2\u001b[39m)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(context)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m( \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m) == \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) == \u001b[32m0\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput text for embedding is empty.\u001b[39m\u001b[33m\"\u001b[39m , \u001b[33m\"\u001b[39m\u001b[33mtext is \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(text))\n\u001b[32m     65\u001b[39m     vector = embeddings.embed_query(text)\n\u001b[32m     66\u001b[39m     obs.update(output=vector)\n",
      "\u001b[31mValueError\u001b[39m: ('Input text for embedding is empty.', \"text is {'messages': [HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={}), ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[SystemMessage(content='Eşti un sistem profesionist de avocatură care vorbeşte limba română şi este specializat în Codul Penal şi legislaţia română.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Ce se intampla daca fur ?', additional_kwargs={}, response_metadata={})])], 'llm_calls': 1}\")",
      "During task with name 'run_chatbot' and id 'c04d22a6-2533-61a8-11a7-1c56f752fbf4'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "messages = [HumanMessage(content=\"Ce se intampla daca fur ?\")]\n",
    "new_state = agent_graph.invoke({\"messages\": messages})\n",
    "for m in new_state[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d5a7a-2b82-4572-9487-97f3222c593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7a0cc-d74a-4a7a-905c-09fba01fe721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ad43f-b7d9-4450-b40f-38becaa79f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
